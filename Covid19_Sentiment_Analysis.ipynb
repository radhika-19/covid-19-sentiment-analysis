{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Covid19 Sentiment Analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w-CxE2zK8UaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install missingno"
      ],
      "metadata": {
        "id": "G4-JqVyp8Vsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we import the libraries"
      ],
      "metadata": {
        "id": "AkKEJiA68b0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd ## data preprocessing\n",
        "import numpy as np\n",
        "import missingno as msno\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt ## graphical analysis\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import re # for regular expressions\n",
        "import pandas as pd \n",
        " \n",
        "import string\n",
        "import nltk # for text manipulation\n",
        "from nltk.stem.porter import *\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "from scipy import stats \n",
        "from sklearn import metrics \n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error, make_scorer,classification_report,confusion_matrix,accuracy_score,roc_auc_score,roc_curve\n",
        "from sklearn.model_selection import train_test_split,cross_val_score,KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "import warnings \n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "ihQVrAAT8ceS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corona_df=pd.read_csv('Corona_NLP_train.csv',  encoding='latin-1')"
      ],
      "metadata": {
        "id": "ZxKWqeXG8lDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corona_df.head()"
      ],
      "metadata": {
        "id": "-QxQG_Ls8nsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corona_df.info()"
      ],
      "metadata": {
        "id": "1PvB4n1J8qzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corona_df.shape"
      ],
      "metadata": {
        "id": "4XPnQk3B8tf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corona_df.TweetAt.value_counts()"
      ],
      "metadata": {
        "id": "DVptn58A8xrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corona_df['Location'].value_counts()"
      ],
      "metadata": {
        "id": "n4Yj-0Hp8yZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corona_df['Sentiment'].value_counts()"
      ],
      "metadata": {
        "id": "DIVYJuVL84uF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualising missing values"
      ],
      "metadata": {
        "id": "wBdxebn387iI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gives positional information of the missing values\n",
        "msno.matrix(corona_df)"
      ],
      "metadata": {
        "id": "vNYNxXHL88a6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the missing values we noticed that there was some kind of missingness in the location so we decided to clean the data first\n",
        "\n",
        "Now in the subsequent steps we will be cleaning the data according to natural language processing we have to remove the unwanted words because machine has to understand the sentiment and we used nltk library which does stemming ,tokenisation and lemmitisation"
      ],
      "metadata": {
        "id": "B6TkDsDI9Fdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in order to remove@user \n",
        "def remove_pattern(input_txt, pattern):\n",
        "    r = re.findall(pattern, input_txt)\n",
        "    for i in r:\n",
        "        input_txt = re.sub(i,'',input_txt)\n",
        "    return input_txt"
      ],
      "metadata": {
        "id": "dkaU14bb9GEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# created a column after removing @ user\n",
        "corona_df['Tweet'] = np.vectorize(remove_pattern)(corona_df['OriginalTweet'], '@[\\w]*')"
      ],
      "metadata": {
        "id": "Vi2hT1200j4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import re has been used for regural expressions"
      ],
      "metadata": {
        "id": "uyAFN6Z49Qjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "corona_df['Tweet'] = corona_df['Tweet'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])"
      ],
      "metadata": {
        "id": "bpf1skOj9OPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. removed stop words,punctuations\n",
        "corona_df['Tweet'] = corona_df['Tweet'].str.replace('[^a-zA-Z#]+',' ')"
      ],
      "metadata": {
        "id": "1kmUU6I89WfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.removed short words\n",
        "corona_df['Tweet'] = corona_df['Tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w) > 2]))"
      ],
      "metadata": {
        "id": "XGCFNt6T9XE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenisation\n",
        "tokenized_tweet = corona_df['Tweet'].apply(lambda x: x.split())"
      ],
      "metadata": {
        "id": "t_1_C1G79ZWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming-Process of reducing infected words to their words stem"
      ],
      "metadata": {
        "id": "p3ECklwl9fkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import *\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# apply stemmer for tokenized_tweet\n",
        "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x])"
      ],
      "metadata": {
        "id": "Oaxf4HCu9b9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# appending/joining two features\n",
        "for i in range(len(tokenized_tweet)):\n",
        "    tokenized_tweet[i] = ' '.join(tokenized_tweet[i])"
      ],
      "metadata": {
        "id": "pXH3_XOY9lVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "New Cleaned dataset after feature engineering"
      ],
      "metadata": {
        "id": "mLhdAo049pOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "covid19 = corona_df[['Tweet','Sentiment']]"
      ],
      "metadata": {
        "id": "5mMouobu1fTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "covid19.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "OvRI3hGg2aMZ",
        "outputId": "cba4fd4a-93a7-4fac-b846-79fff8694dec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Tweet           Sentiment\n",
              "0                                                                Neutral\n",
              "1  advice Talk your neighbours family exchange ph...            Positive\n",
              "2  Coronavirus Australia Woolworths give elderly ...            Positive\n",
              "3  food stock not the only one which empty PLEASE...            Positive\n",
              "4  ready supermarket during the #COVID outbreak N...  Extremely Negative\n",
              "5  news the region first confirmed COVID case cam...            Positive\n",
              "6  Cashier grocery store was sharing his insights...            Positive\n",
              "7  Was the supermarket today Didn buy toilet pape...             Neutral\n",
              "8  Due COVID our retail store and classroom Atlan...            Positive\n",
              "9  For corona prevention should stop buy things w...            Negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7aea1607-7918-4124-9180-fc4b9d8e5de2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>advice Talk your neighbours family exchange ph...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Coronavirus Australia Woolworths give elderly ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>food stock not the only one which empty PLEASE...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ready supermarket during the #COVID outbreak N...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>news the region first confirmed COVID case cam...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Cashier grocery store was sharing his insights...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Was the supermarket today Didn buy toilet pape...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Due COVID our retail store and classroom Atlan...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>For corona prevention should stop buy things w...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7aea1607-7918-4124-9180-fc4b9d8e5de2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7aea1607-7918-4124-9180-fc4b9d8e5de2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7aea1607-7918-4124-9180-fc4b9d8e5de2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing stopwords"
      ],
      "metadata": {
        "id": "XL6F8-wR9zvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "covid19[\"Tweet\"] = covid19[\"Tweet\"].str.lower()#.str.split()"
      ],
      "metadata": {
        "id": "ZVtfSNnL90ZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "hJwXSOyL95e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')"
      ],
      "metadata": {
        "id": "w6eNXOMP96Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "covid19['Tweet'].apply(lambda x: [item for item in x if item not in stop])"
      ],
      "metadata": {
        "id": "38tAF3IU99FY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividing the data into 80 and 20"
      ],
      "metadata": {
        "id": "bTzyvxmM-Cjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train,valid = train_test_split(covid19,test_size = 0.2,random_state=0,stratify = covid19.Sentiment.values)"
      ],
      "metadata": {
        "id": "7Ez3vvlv-DHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "stop = list(stopwords.words('english'))\n",
        "vectorizer = CountVectorizer(decode_error = 'replace',stop_words = stop)\n",
        "\n",
        "X_train = vectorizer.fit_transform(train.Tweet.values)\n",
        "X_valid = vectorizer.transform(valid.Tweet.values)\n",
        "\n",
        "y_train = train.Sentiment.values\n",
        "y_valid = valid.Sentiment.values\n"
      ],
      "metadata": {
        "id": "SBJ58WW43D3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Classifier is maximum used in nlp becuase it gives much accurate results as the answer is based on the no of trees"
      ],
      "metadata": {
        "id": "sVGqfb_F-Oky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "iTq3aIz7-QX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Importing library to check accuracy\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
      ],
      "metadata": {
        "id": "X_nNbsVg-W8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_predict = rf.predict(X_valid)\n",
        "rf_accu = accuracy_score(y_valid,rf_predict)\n",
        "print(\"Training accuracy Score    : \",rf.score(X_train,y_train))\n",
        "print(classification_report(rf_predict,y_valid))"
      ],
      "metadata": {
        "id": "nxmsLgQB-aK0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}